<div class="entry-content">
<div class="section">
<h3><a class="keyword" href="http://d.hatena.ne.jp/keyword/Python">Python</a> &amp; <a class="keyword" href="http://d.hatena.ne.jp/keyword/OpenCV">OpenCV</a>でやってみました</h3>
<p><span itemscope="" itemtype="http://schema.org/Photograph"><img alt="f:id:s51517765:20210822220254p:plain" class="hatena-fotolife" height="868" itemprop="image" loading="lazy" src="https://cdn-ak.f.st-hatena.com/images/fotolife/s/s51517765/20210822/20210822220254.png" title="" width="1199"/></span><br/>
<a class="keyword" href="http://d.hatena.ne.jp/keyword/OpenCV">OpenCV</a>でカメラ画像を取り込み、顔検出してその場所と大きさに調整して他の画像を載せた動画を作ります。<br/>
基本的なところは下の参考サイト組み合わせです。</p><p>まず、動画画像から顔を抽出するには、<a class="keyword" href="http://d.hatena.ne.jp/keyword/OpenCV">OpenCV</a>で行います。<br/>
<a class="keyword" href="http://d.hatena.ne.jp/keyword/GitHub">GitHub</a>から好きなモデルを選択しますが、ここでは正面を向いた顔の抽出を行いました。<br/>
<a href="https://github.com/opencv/opencv/tree/master/data/haarcascades">https://github.com/opencv/opencv/tree/master/data/haarcascades</a></p>
<pre class="code lang-python" data-lang="python" data-unlink="">cascade_path = <span class="synConstant">"haarcascade_frontalface_default.xml"</span>
<span class="synComment"># カスケード分類器の特徴量を取得する</span>
cascade = cv2.CascadeClassifier(cascade_path)
</pre><p>カメラで動画を取得します。<br/>
引数は複数のカメラ（USBカメラなど）があるときは1とか2にします。<br/>
ここではPCの内蔵カメラ（Web会議などに使うインカメラ）を使うので0を指定します。</p>
<pre class="code lang-python" data-lang="python" data-unlink="">cap = cv2.VideoCapture(<span class="synConstant">0</span>)
</pre><p>上書きする画像を取得します。<br/>
ここでは、画像背景を透過にしたいので<a class="keyword" href="http://d.hatena.ne.jp/keyword/PNG">PNG</a>で取得します。<br/>
ア<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%B3%A5%F3%B2%E8">イコン画</a>像を加工して使用しました。</p>
<pre class="code lang-python" data-lang="python" data-unlink="">faceImg = cv2.imread(<span class="synConstant">'s51517765.png'</span>, cv2.IMREAD_UNCHANGED)
</pre><p>動画から顔を認識します。<br/>
認識出来たら、少し大きめ（130%）に画像を調整します。<br/>
顔認識と同じサイズでは頭や顎が出てしまうためです。<br/>
また、拡大した分座標を中心が一致するようにoffsetします。</p>
<pre class="code lang-python" data-lang="python" data-unlink="">facerect = cascade.detectMultiScale(image_gray, scaleFactor=<span class="synConstant">1.1</span>, minNeighbors=<span class="synConstant">2</span>, minSize=(<span class="synConstant">30</span>, <span class="synConstant">30</span>))
<span class="synStatement">if</span> <span class="synIdentifier">len</span>(facerect) &gt; <span class="synConstant">0</span>:
        faceImg = cv2.resize(faceImg, ((<span class="synIdentifier">int</span>)(rect[<span class="synConstant">2</span>]*<span class="synConstant">1.3</span>), (<span class="synIdentifier">int</span>)(rect[<span class="synConstant">3</span>]*<span class="synConstant">1.3</span>)), cv2.IMREAD_UNCHANGED)
rect[<span class="synConstant">0</span>] -= rect[<span class="synConstant">2</span>]*<span class="synConstant">0.15</span>  <span class="synComment"># x_offset</span>
rect[<span class="synConstant">1</span>] -= rect[<span class="synConstant">3</span>]*<span class="synConstant">0.15</span>  <span class="synComment"># y_offset</span>
</pre><p>透過処理をして画像を重ねます。</p>
<pre class="code lang-python" data-lang="python" data-unlink="">  frame[rect[<span class="synConstant">1</span>]:rect[<span class="synConstant">1</span>]+faceImg.shape[<span class="synConstant">0</span>],rect[<span class="synConstant">0</span>]:rect[<span class="synConstant">0</span>]+faceImg.shape[<span class="synConstant">1</span>]] = frame[rect[<span class="synConstant">1</span>]:rect[<span class="synConstant">1</span>]+faceImg.shape[<span class="synConstant">0</span>], rect[<span class="synConstant">0</span>]:rect[<span class="synConstant">0</span>]+faceImg.shape[<span class="synConstant">1</span>]] * (<span class="synConstant">1</span> - faceImg[:, :, <span class="synConstant">3</span>:] / <span class="synConstant">255</span>) + faceImg[:, :, :<span class="synConstant">3</span>] * (faceImg[:, :, <span class="synConstant">3</span>:] / <span class="synConstant">255</span>)
</pre><p>動画を表示します。</p>
<pre class="code lang-python" data-lang="python" data-unlink="">cv2.imshow(<span class="synConstant">'cv2'</span>, frame)
</pre><p>1st tryがこんな感じですが、首元や背景に余計な顔誤認識があります。</p><blockquote class="twitter-tweet" data-conversation="none" data-lang="ja"><p dir="ltr" lang="ja"><a class="keyword" href="http://d.hatena.ne.jp/keyword/Python">Python</a>&amp;<a class="keyword" href="http://d.hatena.ne.jp/keyword/OpenCV">OpenCV</a>で顔を隠すのやってみた。 <a href="https://t.co/VpHU10PRfa">pic.twitter.com/VpHU10PRfa</a></p>— とりてん (@s51517765) <a href="https://twitter.com/s51517765/status/1429006279444287490?ref_src=twsrc%5Etfw">2021年8月21日</a></blockquote> <script async="" charset="utf-8" src="https://platform.twitter.com/widgets.js"></script> <p>そこで、少し工夫をしました。<br/>
顔の認識サイズを<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B0%DC%C6%B0%CA%BF%B6%D1">移動平均</a>で取得し、これに対して大きく外れている場合は誤認識とみなしてスキップします。<br/>
顔認識の縦横サイズを両方採用しましたが、ほぼ同じサイズなのでどちらかでも大丈夫かもしれません。<br/>
ここでは、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B0%DC%C6%B0%CA%BF%B6%D1">移動平均</a>の95%以下をスキップするようにしました。</p>
<pre class="code lang-python" data-lang="python" data-unlink="">aveSize = aveSize*<span class="synConstant">0.8</span>+rect[<span class="synConstant">2</span>]*<span class="synConstant">0.1</span>+rect[<span class="synConstant">3</span>]*<span class="synConstant">0.1</span>
thresh = aveSize*<span class="synConstant">0.95</span>  <span class="synComment"># 移動平均の95%以上を閾値</span>
<span class="synStatement">if</span> rect[<span class="synConstant">2</span>] &lt; thresh <span class="synStatement">or</span> rect[<span class="synConstant">3</span>] &lt; thresh:
       <span class="synStatement">break</span>
</pre><p>安定するようになりました。</p><blockquote class="twitter-tweet" data-conversation="none" data-lang="ja"><p dir="ltr" lang="ja"><a class="keyword" href="http://d.hatena.ne.jp/keyword/Python">Python</a>&amp;<a class="keyword" href="http://d.hatena.ne.jp/keyword/OpenCV">OpenCV</a>で顔を隠すのやってみた（Ver.2）。<br/><br/>小さい顔が入り込んでしまう（間違った認識がされる）のを改良。 <a href="https://t.co/nEHyBvVpQY">pic.twitter.com/nEHyBvVpQY</a></p>— とりてん (@s51517765) <a href="https://twitter.com/s51517765/status/1429012428193288192?ref_src=twsrc%5Etfw">2021年8月21日</a></blockquote> <script async="" charset="utf-8" src="https://platform.twitter.com/widgets.js"></script>
</div>
<div class="section">
<h3>まとめ</h3>
<p>別件で<a class="keyword" href="http://d.hatena.ne.jp/keyword/Python">Python</a>でカメラを扱う案件があってカメラの使い方を調べたので、テレビでたまに見る似顔絵で顔を隠すやつをやってみました。<br/>
Zoomミーティングとかで使ってみようかな。</p>
</div>
<div class="section">
<h3><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BD%A1%BC%A5%B9%A5%B3%A1%BC%A5%C9">ソースコード</a></h3>
<pre class="code lang-python" data-lang="python" data-unlink=""><span class="synComment">#!/usr/bin/env python</span>
<span class="synComment"># -*- coding: utf-8 -*-</span>

<span class="synPreProc">import</span> cv2
<span class="synPreProc">import</span> os

<span class="synComment"># https://github.com/opencv/opencv/tree/master/data/haarcascades</span>
cascade_path = <span class="synConstant">"haarcascade_frontalface_default.xml"</span>
<span class="synComment"># カスケード分類器の特徴量を取得する</span>
cascade = cv2.CascadeClassifier(cascade_path)


<span class="synStatement">def</span> <span class="synIdentifier">VideoCapt</span>():
    cap = cv2.VideoCapture(<span class="synConstant">0</span>)  <span class="synComment"># カメラが複数あるときは 0を1や2にする</span>
    aveSize = <span class="synConstant">0</span>
    count = <span class="synConstant">0</span>
    <span class="synStatement">while</span> cap.isOpened():
        <span class="synStatement">try</span>:
            <span class="synComment"># マネしたい人はイラストやのぶたさんでもつかってね</span>
            <span class="synComment"># https://www.irasutoya.com/2017/09/blog-post_966.html</span>
            faceImg = cv2.imread(<span class="synConstant">'s51517765.png'</span>, cv2.IMREAD_UNCHANGED)
            _, frame = cap.read()
            <span class="synComment"># グレースケール変換</span>
            image_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            facerect = cascade.detectMultiScale(
                image_gray, scaleFactor=<span class="synConstant">1.1</span>, minNeighbors=<span class="synConstant">2</span>, minSize=(<span class="synConstant">30</span>, <span class="synConstant">30</span>))

            <span class="synComment"># print(facerect)</span>
            color = (<span class="synConstant">255</span>, <span class="synConstant">255</span>, <span class="synConstant">255</span>)  <span class="synComment"># 白</span>

            <span class="synComment"># 検出した場合</span>
            <span class="synStatement">if</span> <span class="synIdentifier">len</span>(facerect) &gt; <span class="synConstant">0</span>:
                <span class="synStatement">for</span> rect <span class="synStatement">in</span> facerect:
                    count += <span class="synConstant">1</span>
                    <span class="synStatement">if</span> count &lt; <span class="synConstant">4</span>:
                        aveSize += (rect[<span class="synConstant">2</span>]+rect[<span class="synConstant">3</span>])/<span class="synConstant">2</span>
                        <span class="synStatement">break</span>
                    <span class="synStatement">elif</span> count == <span class="synConstant">4</span>:
                        aveSize += (rect[<span class="synConstant">2</span>]+rect[<span class="synConstant">3</span>])/<span class="synConstant">2</span>
                        aveSize /= <span class="synConstant">5</span>
                    <span class="synStatement">else</span>:
                        aveSize = aveSize*<span class="synConstant">0.8</span>+rect[<span class="synConstant">2</span>]*<span class="synConstant">0.1</span>+rect[<span class="synConstant">3</span>]*<span class="synConstant">0.1</span>
                    thresh = aveSize*<span class="synConstant">0.95</span>  <span class="synComment"># 移動平均の95%以上を閾値</span>
                    <span class="synStatement">if</span> rect[<span class="synConstant">2</span>] &lt; thresh <span class="synStatement">or</span> rect[<span class="synConstant">3</span>] &lt; thresh:
                        <span class="synStatement">break</span>
                    <span class="synComment"># 検出した顔を囲む矩形の作成</span>
                    <span class="synComment">#cv2.rectangle(frame, tuple(rect[0:2]), tuple( rect[0:2]+rect[2:4]), color, thickness=2)</span>
                    faceImg = cv2.resize(
                        faceImg, ((<span class="synIdentifier">int</span>)(rect[<span class="synConstant">2</span>]*<span class="synConstant">1.3</span>), (<span class="synIdentifier">int</span>)(rect[<span class="synConstant">3</span>]*<span class="synConstant">1.3</span>)), cv2.IMREAD_UNCHANGED)

                    rect[<span class="synConstant">0</span>] -= rect[<span class="synConstant">2</span>]*<span class="synConstant">0.15</span>  <span class="synComment"># x_offset</span>
                    rect[<span class="synConstant">1</span>] -= rect[<span class="synConstant">3</span>]*<span class="synConstant">0.15</span>  <span class="synComment"># y_offset</span>
                    frame[rect[<span class="synConstant">1</span>]:rect[<span class="synConstant">1</span>]+faceImg.shape[<span class="synConstant">0</span>],
                          rect[<span class="synConstant">0</span>]:rect[<span class="synConstant">0</span>]+faceImg.shape[<span class="synConstant">1</span>]] = frame[rect[<span class="synConstant">1</span>]:rect[<span class="synConstant">1</span>]+faceImg.shape[<span class="synConstant">0</span>],
                                                                    rect[<span class="synConstant">0</span>]:rect[<span class="synConstant">0</span>]+faceImg.shape[<span class="synConstant">1</span>]] * (<span class="synConstant">1</span> - faceImg[:, :, <span class="synConstant">3</span>:] / <span class="synConstant">255</span>) + <span class="synSpecial">\</span>
                        faceImg[:, :, :<span class="synConstant">3</span>] * (faceImg[:, :, <span class="synConstant">3</span>:] / <span class="synConstant">255</span>)
                    cv2.imshow(<span class="synConstant">'cv2'</span>, frame)

        <span class="synStatement">except</span>:
            <span class="synStatement">pass</span>
        <span class="synStatement">if</span> cv2.waitKey(<span class="synConstant">1</span>) &amp; <span class="synConstant">0xFF</span> == <span class="synIdentifier">ord</span>(<span class="synConstant">'q'</span>):
            <span class="synStatement">break</span>
    cap.release()
    <span class="synIdentifier">print</span>(<span class="synConstant">"Camera is closed."</span>)


<span class="synIdentifier">print</span>(<span class="synConstant">'Python Active:      '</span>, os.getcwd())
path = os.path.dirname(__file__)
<span class="synIdentifier">print</span>(<span class="synConstant">'Script location:     '</span>, path)
os.chdir(path)

<span class="synStatement">if</span> __name__ == <span class="synConstant">'__main__'</span>:
    VideoCapt()
</pre>
</div>
<div class="section">
<h3>参考</h3>
<p><iframe class="embed-card embed-webcard" frameborder="0" scrolling="no" src="https://hatenablog-parts.com/embed?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Ftree%2Fmaster%2Fdata%2Fhaarcascades" style="display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;" title="opencv/data/haarcascades at master · opencv/opencv"></iframe><cite class="hatena-citation"><a href="https://github.com/opencv/opencv/tree/master/data/haarcascades">github.com</a></cite><br/>
<iframe class="embed-card embed-webcard" frameborder="0" scrolling="no" src="https://hatenablog-parts.com/embed?url=https%3A%2F%2Fqiita.com%2FFukuharaYohei%2Fitems%2Fec6dce7cc5ea21a51a82" style="display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;" title="【入門者向け解説】openCV顔検出の仕組と実践(detectMultiScale) - Qiita"></iframe><cite class="hatena-citation"><a href="https://qiita.com/FukuharaYohei/items/ec6dce7cc5ea21a51a82">qiita.com</a></cite><br/>
<iframe class="embed-card embed-webcard" frameborder="0" scrolling="no" src="https://hatenablog-parts.com/embed?url=https%3A%2F%2Flaboratory.kazuuu.net%2Fplay-video-in-python-using-opencv%2F" style="display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;" title="OpenCVを使用してPythonで動画（ビデオ）を再生する"></iframe><cite class="hatena-citation"><a href="https://laboratory.kazuuu.net/play-video-in-python-using-opencv/">laboratory.kazuuu.net</a></cite><br/>
<iframe class="embed-card embed-webcard" frameborder="0" scrolling="no" src="https://hatenablog-parts.com/embed?url=https%3A%2F%2Fcode-graffiti.com%2Fblending-images-with-opencv-in-python%2F%23toc6" style="display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;" title="【Python】OpenCVで画像を合成する – addWeighted, bitwise演算, ROI"></iframe><cite class="hatena-citation"><a href="https://code-graffiti.com/blending-images-with-opencv-in-python/#toc6">code-graffiti.com</a></cite><br/>
<iframe class="embed-card embed-webcard" frameborder="0" scrolling="no" src="https://hatenablog-parts.com/embed?url=https%3A%2F%2Fqiita.com%2Fsmatsumt%2Fitems%2F923aefb052f217f2f3c5" style="display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;" title="アルファチャンネルつき png を透過画像で貼り付ける with Python/OpenCV - Qiita"></iframe><cite class="hatena-citation"><a href="https://qiita.com/smatsumt/items/923aefb052f217f2f3c5">qiita.com</a></cite></p>
</div>
</div>